%At the end of your thesis you can attach resources such as source code (or something like ASCII code table) that would improve the completeness of your thesis.

\section*{Appendix A - Implementation}
\appendix
\addcontentsline{toc}{section}{Appendix A - Implementation}
\markboth{Appendix A}{}
\label{sec:appendix-impl} 

%TODO crucial parts of the implementation 
%TODO additional tables, measures 

%Implementation â€“ in implementation section you should mention the tools that you use to implement, the target environment (e.g. linux, windows). Limitations (e.g. buffer sizes, connections number).

\subsection{GeneRec} 
\label{sec:appendix-impl-generec} 

Activation is computed as in \ref{eq:models-generec-activation}.

\subsubsection{Bias} 
%TODO reformulate
%TODO add more recent citations 
%TODO add results with / without bias 
%TODO parse references 
The use of such biases in neural networks has been discussed in the context of the fundamental bias/variance tradeoff \citet{geman1992neural}. This tradeoff emphasizes the fact that biases that are appropriate for the task can greatly facilitate learning and generalization by reducing the level of variance, where variance reflects the extent to which parameters are underconstrained by learning, and thus free to vary, causing random errors in generalization. These biases are also known as regularizers \citet{poggio1990networks}. However, inappropriate biases can obviously hurt performance by introducing systematic errors, such that there is no such thing as a single universally beneficial set of biases (Wolpert, 1996a; Wolpert, 1996b). 

\subsubsection{Fluctuation} 
\label{sec:generec-fluctuation}

Asymmetric BIA \ref{sec:our-bal-recirc}.

%\paragraph{Recirculation step} %====================
If no stationary point solution is found after MAX\_ITERATION then we set the result to avarage of the last two activations. This lead to 80\% less fluctuation. But still occured: 
\begin{itemize}
\item Big fluctuation: 0.9591299483462391
\item Not enough iterations: 20
\item Even if MAX\_ITERATION = 200 then max fluctuation still could be arbitrary and oscilating.
\end{itemize} 

%\paragraph{Interesting} %====================
\begin{itemize} 
  \item oscilation in iteration could occur randomly (just in some epochs and it will completely change the network) 
  \item when using averages, it's less probable that a fluctuation will occur 
  \item setting MAX\_iteration much higher doesn't affect performance. About 50 is enough but 20 is not. 
\end{itemize} 
  
%\paragraph{Conclusion} %====================
Symmetric weights haven't helped BAL (35\%) - no param selection
Using bothward GeneRec (60\%) - no param selection 
  Forgot to symmetric init -> no perceivable change 
In both cases (almost) no fluctuation 

Non-symmetric case, fluctuation in about 1/5 cases 
  About 30\% success 
  About 3-33 iterations needed to settle, very network dependent 
  About 50 - 5000 epochs needed 

IDEA: maybe bad implementation of backward
      using iterative activation has almost no reason (bothward is the generec idea) 


\subsubsection{Initial weight distribution} 
\label{sec:our-sigma} 

