% The theory and concepts of your work. For example, if you work on compiler you can mention about how compiler works without getting much into detail.

\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\Bx}{{\bf x}}
\newcommand{\By}{{\bf y}}
\newcommand{\Bh}{{\bf h}}
\newcommand{\Bw}{{\bf w}}
\newcommand{\Bc}{{\bf c}}

In this section we will describe the basics of artificial neural networks. We will also introduce the notation used in this work. Note that the definitions and notations vary through the literature. We use the one which the author is familiar with. For the reader who is comfortable with this topic we recommend to skip this section and go to related models \ref{overview-models}. 

\input{theory-perceptron} 
\label{sec:perceptron} 

%=============================================================
\subsubsection{Multilayer Feedword Networks} 

In general we can define a neural network as a directed weighted graph. Each \emph{unit} (vertex) has its \emph{activation} and usually it changes in discrete time. The \emph{state} of a neural network are current \emph{weights} of edges and current activations. 

\paragraph{Input layer.}
Subset of units on which the input values are \emph{clamped}. If the input value for unit $x_i$ is $s_i$ then the activation for unit $x_i$ is simply $s_i$. 

\paragraph{Output layer.}
Similary as the input layer, output layer is a subset of units which activations we treat as the output. 

\paragraph{Hidden layer.}
Set of units which are both not input or output. 
