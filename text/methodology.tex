%Experimental Methodology – in this section you should describe the environment where you did the experiments, tools you used (compilers, libraries, profilers, simulators) and benchmarks that you used. Here you should tell what is your evaluation criteria (e.g. speedup) and metrics (e.g. throughput). Anything important that was made to conduct the experiments should be here (e.g. preparing traces for reproducing deterministic executions). If your experimental methodology has limitations you should mention them here (e.g. when using simulator you used small data input sets).

\section{Methodology and Design}

\subsection{Models}

\subsubsection{Previous} 

\begin{itemize} 
\item CHL
\item GeneRec 
\item BAL
\end{itemize}  

\subsubsection{Candidate selection} 
Hidden distance (over 70\%) over in triangle (68.3 \%). 

\input{tried-bal-recirculation}
  
\subsubsection{Long training} 
even after 800,000 epochs there are some networks for which the error change

\subsubsection{Other} 
\begin{itemize} 
\item Momentum
\item Weight initialization 
\item Dynamic weight lambda (no change after few tries TODO test again) 
\item Batch mode (i.e. no shuffle and therefore deterministic)
\item Multilayer GeneRec - 42\% on handwritten digit recognition 
\item Dropout TODO (5\%,10\%,20\%,50\% chances)
\item TODO Noise 
\item TODO !Presenting in-out on which it has errors (based on rerun shuffle data). 
\end{itemize} 

\subsection{Evaluation methods} 

\subsubsection{Success rate} 

\begin{itemize}
\item Overall success. 
\item Bit success. 
\item Pattern success. 
\end{itemize} 

\subsubsection{Epochs needed for convergence} 



\subsection{Experiments}  

\subsubsection{4-2-4 Encoder} 

TODO: Write it as "Because BAL had significantly worse performance on this experiment we tried to analyse what are the reasons and propose improvements". 

To compare the performance of BAL with GeneRec, we ran tests using the well-
known 4-2-4 encoder task, following O’Reilly \cite{o1996bio}. We investigated the convergence
of BAL and the number of required training epochs as a function of the learning
rate. Fig. 1 shows the convergence success for 100 networks and the average
numbers of epochs needed. The simulations showed that convergence of BAL
depends on the learning rate, with the highest number of 65\% successful runs
achieved for $\lambda = 0.9$ \cite{farkas2013bal}. For comparison, O’Reilly \cite{o1996bio} reports 90\% success for basic GeneRec algorithm and 56\% for a symmetric modification of GeneRec and its
modification equivalent to CHL. In sum, probability of BAL convergence is lower
than that of basic GeneRec rule, but comparable to its symmetric versions. We
expect that the smaller number of successful runs is in both cases influenced by
the bidirectional nature of the weight update.

\subsubsection{Complex Binary Vector Associations} 

TODO: Write it as "Small scale graphical task to see the reconstruction" 
We evaluated the network performance on n–to–1 data associations, motivated
by the sensory-motor mappings between distributed patterns. For this purpose
we created low-dimensional sparse binary codes, 16-dimensional vectors ($4 \times 4$
map) with k = 3 active units with n = 4. For each target (y), these four
patterns (x) were assumed to have nonzero overlap. Again, we searched for
optimal $\lambda$ and $n_H$ (Fig. 5). The best performance was achieved using $\lambda$ $\approx$ 1. We
can observe that the ambiguity in the data association causes the network to
produce errors in B direction. For the best $\lambda$ the networks yielded patSuccB $\approx$
4\% and $bitSucc^B \approx 86\%$, which means that the networks made small errors in
most patterns. This could be expected since the network cannot know which of
the four (x) patterns is to be reconstructed. It is known, that a network trained
to associate more binary target patterns with one pattern tends to produce a
mesh of outputs, weighed by their frequency of occurrence in the training set.
Examples of network outputs are illustrated in Fig. 6.

\begin{center} 
\includegraphics{img/cbva_back_repre.png} 
\end{center} 

\subsubsection{Hand-written Digits} 
TODO: Write overview as "High dimensional graphical task to see backward representation and compare it with a bunch of other models" 
TODO: Compare results: \url{http://yann.lecun.com/exdb/mnist/} 
Data from MNIST database \cite{lecun1998gradient}. 



