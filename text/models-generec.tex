\subsubsection{Generalized recirculation}
\label{models-generec} 

TODO rewrite and shorten a little 
TODO use previously defined as CHL and Recirculation

\paragraph{Introduction.} 

The \emph{Generalized recirculation algorithm}, or \emph{GeneRec}, was developed by \citet{o1996bio}. It's a supervised algorithm which in comparison with Backpropagation \ref{models-bp} is argued to be a more biologically plausible model \citep{o1998six, o2001generalization, da2011advances, schneider2009application}. In summary, GeneRec is a combination of CHL \ref{models-chl} and the Recirculation algorithm \ref{models-recirc}. It overcomes limitations of the Recirculation algorithm to be an encoder by having a three layer network. For the error computation a backward weight matrix from output layer to hidden layer is used and the learning rule is derived from the CHL learning rule~\ref{eq:models-chl-learning-rule}. It could be proven that GeneRec, as Backpropagation, could learn arbitrary input--output mappings \citep{o1996bio}. 

GeneRec uses three weight matrices $W_{IH}$, $W_{HO}$ and $W_{OH}$ for the input--hidden, hidden--output and output--hidden weights. It also has the \quotes{-} and \quotes{+} phases as CHL and uses the non--symmetric version of the CHL rule: 
\begin{equation}
  \label{eq:models-generec-learning-rule}
  \Delta w_{ij} = \lambda \ a^{-}_i(a^{+}_j - a^{-}_j)
\end{equation}

\begin{table}
  \centering
  \begin{tabular}{|cccc|}
    \hline
    Layer & Phase & Net Input & Activation\\
    \hline
    Input (s)    & $-$ & - & $s_i$ = stimulus input\\
    \hline
    Hidden (h)   & $-$ & \hspace{0.3cm}$\eta^{-}_j = \sum_i w_{ij}s_i + \sum_k w_{kj}o^{-}_k$\hspace{0.3cm} &
    $h^{-}_j = \sigma(\eta^{-}_j)$\hspace{0.3cm}\\
          &  +  & $\eta^{+}_j = \sum_{i}w_{ij}s_i + \sum_k w_{kj}o^{+}_k$ & $h^{+}_{j} = \sigma(\eta^{+}_j)$ \\
    \hline
    Output (o) & $-$ & $\eta^{-}_k = \sum_j w_{jk}h_j$ & $o^{-}_k = \sigma(\eta^{-}_k)$\\
           &  +  & - & $o^{+}_k$ = target output \\
    \hline
  \end{tabular}
  \caption{Equilibrium network variables in GeneRec model \citet{o1996bio}. We can see inspiration from the Recirculation algorithm \ref{models-recirc} and a correspondence between $T$ and GeneRec phases. In particular $s^{-} \approx T=0$, $h^{-} \approx T=1$, $o^{-} \approx T=2$ and $h^{+}$ corresponds to $T=3$.}
  \label{tab:generec}
\end{table}

The basic weight update rule in GeneRec is:
\begin{equation}
\label{eq:generec}
\end{equation}
where $a^{-}_p$ denotes the presynaptic and $a^{-}_q$ denotes the postsynaptic unit activation in minus phase, $a^{+}_p$ is the presynaptic activation from plus phase (in output-to-hidden direction) and $\lambda$ denotes the learning rate. The learning rule given in Eq.~\ref{eq:generec} is applied to both input-hidden and hidden-output weights.  Due to the lack of space, the reader is left to consult the original paper \citet{o1996bio} regarding the underlying math behind the derivation of the GeneRec learning rule.

\paragraph{Minus phase.} When units xi are presented to the input layer A, there is the propagation of this stimulus to the hidden layer B (bottom-up propagation) (figure 1). At the same time, the previous output ok propagates from the output layer C to the hidden layer B (top- down propagation) (figure 2). Then the hidden activation \emph{minus} - minus phase - ($h^-$ ) is generated (sum of bottom-up and top-down propagations). The activation function $\sigma$ is sigmoid. Equation 1 shows the hidden activation calculus for one hidden unit j. wij are the synaptic weights from the input layer to the hidden layer and wjk are the synaptic weights from the hidden layer to the output layer (which are the same as the weights from the output layer to the hidden layer, because reciprocal weights are symmetric in GeneRec, that is, wjk = wkj \citet{o1996bio}). ok(t-1) is the previous output (output on time t - 1) \citet{orru2008sabio}.

$$h_j^- = \sigma \left(\sum_{i=0}^A w_{ij} \cdot x_i + \sum_{k=1}^C w_{jk} \cdot o_k(t-1)\right)$$

Finally, the real output ok(t) is generated through the propagation of the \emph{minus} layer activation to the output layer (figure 3), shown for one output unit k by equation 2 \citet{o1996bio}. Notice that the architecture employed is bi-directional. Recall that ok (t) (the current output on time t) is used in order to differentiate it from ok (t - 1) (the previous output on time t - 1).

\begin{center} 
\includegraphics[width=0.5\textwidth]{img/generec_minus_phase.png} \citet{orru2008sabio} 
\end{center} 

\paragraph{Plus phase.} Units xi are presented again to the input layer A; there is the propagation of this stimulus to the hidden layer B (bottom-up propagation) (figure 4). At the same time, the desired output yk propagates from the output layer C to the hidden layer B (top- down propagation) (figure 5). Then the hidden activation + \emph{plus} - plus phase - (hj) is generated, summin bottom-up and top-down propagations (equation 3) \citet{o1996bio}, \citet{orru2008sabio}.

$$h_j^+ = \sigma\left( \sum_{i=0}^A w_{ij} \cdot x_i + \sum_{k=1}^C w_{jk} y_k \right)$$

\begin{center} 
\includegraphics[width=0.5\textwidth]{img/generec_plus_phase.png} \citet{orru2008sabio} 
\end{center} 

In order to make learning possible, synaptic weights $w$ are updated, based on h-, j  $h^+_j$, $o_k$ , $y_k$, $x_i$, and the learning rate $\eta$ (equations 4 and 5).

%TODO equation labels with intext references 
$$\Delta w_{jk} = \eta(y_k - o_k(t)) h^-_j $$

$$\Delta w_{ij} = \eta(h^+_j - h^-_j) x_i$$

Finally, O’Reilly \citet{o1998six} suggests, unlike backpropagation, that the teaching signal is just another state of “experience” in the network, that is, in GeneRec algorithm the teaching signal is exactly the “top-down” activation in the plus-phase.

TODO reformulate 
It was recently shown that backpropagation can be implemented in a more biologically plausible fashion using bidirectional activation propagation in an interactive network using the GeneRec algorithm \citet{o1996bio}, which is a generalization of the recirculation algorithm \citet{hinton1988learning}. In GeneRec, error information is propagated as two separate terms via standard activation propagation mechanisms in interactive networks, and the difference between these terms (which is the error signal) can be plausibly computed using the synaptic modification mechanisms underlying long term potentiation and depression (LTP/LTD). Versions of the GeneRec algorithm are equivalent to the other known ways of implementing powerful error-driven learning using interactive activation propagation instead of direct error propagation (e.g., the deterministic Boltzmann machine \citet{hinton1989deterministic} and Contrastive Hebbian Learning \citet{movellan1990contrastive}). Thus, several different approaches converge on the idea that the way to perform error-driven learning in a more biologically plausible manner is to use interactive networks, where error signals are communicated via top-down activation propagation \citet{o2001generalization}.

%Copy from \citet{da2011advances} 

%TODO \citet{nawrocki2012monitoring}.
%TODO Some improvements \citet{da2008biological}. 

To assess the effect of interactivity, two different networks were compared on the combinatorial generalization task, a standard feedforward backpropagation network, and an interactive GeneRec network using the symmetric, midpoint variation learning rule which is equivalent to contrastive Hebbian learning (CHL) or a deterministic Boltzmann machine (DBM) \citet{o1996bio}, \citet{o2001generalization}. 
 
\footnote{TODO: How to cope with biases (which are not symmetric)? We haven't found how GeneRec uses the Bias neuron.} 
