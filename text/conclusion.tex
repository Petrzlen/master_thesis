% ==================== 16. Conclusion ========================
% This chapter should conclude on your contribution. It should highlight the key results from the research work. In this section, you should avoid mentioning new terms and statements not discussed throughout the main text. Also general aspects of the research work shouldn’t be repeated here. Conclusion shouldn’t be the abstract written in past tense. The conclusion should derive the important facts out of your work and results that you obtained.
%=== ZAVER ====
%\begin{itemize} 
%\item   toto je otvorene
%\item   toto vyzera tazko
%\item   tymto by sme sa zaoberali dalej (Future work) 
%\end{itemize} 

\section*{Conclusion}
\markboth{CONCLUSION}{}
\addcontentsline{toc}{section}{Conclusion}
\label{sec:conclusion} 

In our work, we proposed and analysed the Two learning rates (TLR) model, a modification of BAL, which increased the success rate from 62.7\% to 93.1\% on the 4-2-4 encoder task. We observed that BAL converges rapidly to the state, when the backward and forward activations converge to the same values. This has inspired our primary hypothesis to explain why BAL had problems learning the 4-2-4 encoder task. Our hypothesis was further confirmed by candidate selection, which selected the network with more distant hidden activations. This increased the success rate from 93.1\% to 99.84\% and reduced the number of epochs needed for convergence from 5845 to 150. Then we applied TLR on the handwritten digit recognition task using the architecture 784--300--10. Although TLR still has a performance gap compared to backpropagation, it achieved far better success rate than original BAL.

We experimented with many different modifications of BAL, notably BAL-recirc, other GeneRec learning rules, dropout and multi-layer GeneRec, but these did not prove to be useful. Standard modifications, such as batch training mode or adding momentum, showed no tendency in increasing the success rate of TLR. We admit that there is a space for improvement on these approaches.

\label{sec:future-work}
%What left unfinished from your work? What are you future plans to develop better your work?
Our work opened several ways to continue the analysis of BAL. For instance, it would be possible to predict success rate from the initial weights, as discussed in Section~\ref{sec:our-weight-init-class}. Another option is to use four learning rates, one for each matrix, or dynamic learning rates for each connection as outlined in Section~\ref{sec:our-dynamic-lambda}. Furthermore, we recommend analysing backward activations which showed counterintuitive behaviour in Figure~\ref{fig:results-tlr-auto4-epoch}. Finally, TLR introduced one more parameter to the network setup and therefore a method for finding best pair learning rates would be usefull. 

%OPT candidate selection TDM 

